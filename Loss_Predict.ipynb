{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will take in a dataset and then predict the loss of the other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Ratio is predicted as \n",
    "\n",
    "Loss Ratio=bytes_sent/bytes_retrans​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "I need to normalize the data first, and the continue from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colunms without any variation:  ['wscale', 'mss', 'pmtu', 'rcvmss', 'advmss', 'rcv_space', 'rcv_ssthresh', 'ssthresh']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset manually using NumPy\n",
    "file_path = \"reno1.log.csv\"  # Update with actual file path\n",
    "# Load the dataset using numpy (semicolon separated)\n",
    "df = pd.read_csv(file_path, delimiter=\";\")  # skip_header=1 if there’s a header row\n",
    "\n",
    "# remove last column, some kind of spacing i\n",
    "# Drop the last column using pandas\n",
    "df = df.iloc[:, :-1]  # Select all rows, and all columns except the last one\n",
    "\n",
    "df['loss_ratio'] = df['bytes_retrans'] / df['bytes_sent']\n",
    "# Identify constant columns\n",
    "constant_columns = [col for col in df.columns if len(df[col].unique()) == 1]\n",
    "\n",
    "constant_columns.append(\"ssthresh\")\n",
    "print(\"colunms without any variation: \", constant_columns)\n",
    "# Drop constant columns from the dataset\n",
    "df = df.drop(columns=constant_columns)\n",
    "\n",
    "# Normalize using Min-Max scaling: (X - min) / (max - min)\n",
    "# data_min = df.min(axis=0)\n",
    "# data_max = df.max(axis=0)\n",
    "# df_normalized = (df - data_min) / (data_max - data_min)\n",
    "\n",
    "# # Now df_normalized is your dataset without the constant columns and normalized\n",
    "# print(df_normalized.iloc[0])\n",
    "# print(df_normalized.iloc[3000])\n",
    "\n",
    "# # Normalize using Min-Max scaling: (X - min) / (max - min)\n",
    "# data_min = np.min(df, axis=0)  # Find min along each column\n",
    "# data_max = np.max(df, axis=0)  # Find max along each column\n",
    "# data_normalized = (df - data_min) / (data_max - data_min)\n",
    "\n",
    "\n",
    "loss_ratio_tensor = torch.tensor(df['loss_ratio'].values, dtype=torch.float32)\n",
    "# Convert to PyTorch tensor\n",
    "#Changed df_normalized back to df first.\n",
    "data_tensor = torch.tensor(df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Ratio tensor:  torch.Size([3600])\n",
      "Data tensor:  torch.Size([3600, 12])\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss Ratio tensor: \", loss_ratio_tensor.shape)\n",
    "print(\"Data tensor: \", data_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data, 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2816, 12]) torch.Size([720, 12])\n",
      "torch.Size([2816]) torch.Size([720])\n",
      "Inputs: torch.Size([64, 12]), Targets: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data_tensor) *0.8)\n",
    "X_train, X_test = data_tensor[64:train_size], data_tensor[train_size:]\n",
    "y_train, y_test = loss_ratio_tensor[64:train_size], loss_ratio_tensor[train_size:]\n",
    "\n",
    "# Print the shapes to verify the split\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64  # You can adjust the batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Example of accessing a batch of data\n",
    "for inputs, targets in train_loader:\n",
    "    print(f'Inputs: {inputs.shape}, Targets: {targets.shape}')\n",
    "    \n",
    "    break  # Only print the first batch for verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LSTM Model used as the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_pt(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM_pt, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM cell\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers = self.num_layers, batch_first = True)\n",
    "        \n",
    "        # Linear layer for final prediction\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, cell_state=None, hidden_state=None):\n",
    "        # Forward pass through the LSTM cell\n",
    "        if hidden_state is None or cell_state is None:\n",
    "            hidden_state = torch.zeros(1, inputs.size(0), 20).to(device)\n",
    "            cell_state = torch.zeros(1, inputs.size(0), 20).to(device)\n",
    "        hidden = (cell_state, hidden_state)\n",
    "        output, new_memory = self.lstm(inputs, hidden)\n",
    "        cell_state, hidden_state = new_memory\n",
    "        output = self.linear(output[:, -1, :])  # Take only the last time step\n",
    "        return output, cell_state, hidden_state, # Return correct order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will implement sliding window next time, but for now, it will only predict the next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is:  torch.Size([64, 12])\n",
      "input is:  torch.Size([64, 1, 12])\n",
      "inputs.size(0) 64\n"
     ]
    }
   ],
   "source": [
    "for inputs,target in train_loader:\n",
    "    print(\"input is: \", inputs.shape)\n",
    "    inputs = inputs.unsqueeze(1).to(device)  # Reshape inputs\n",
    "    print(\"input is: \", inputs.shape)\n",
    "\n",
    "    print(\"inputs.size(0)\", inputs.size(0))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader,num_layers, hidden_size, num_epochs, learning_rate, device, ):\n",
    "    # Set the loss function and optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss=0\n",
    "        hidden_state, cell_state = None, None   \n",
    "        for inputs, targets in dataloader: \n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.unsqueeze(1).to(device)  # Reshape inputs\n",
    "            targets = targets.unsqueeze(1).to(device)\n",
    "            # Initialize hidden state and cell state for each batch\n",
    "\n",
    "            if hidden_state is not None:\n",
    "                hidden_state = hidden_state.detach()\n",
    "            if cell_state is not None:\n",
    "                cell_state = cell_state.detach()\n",
    "\n",
    "            # Forward pass\n",
    "            output, cell_state, hidden_state = model(inputs.to(device),cell_state, hidden_state)\n",
    "            # Calculate loss\n",
    "            loss += criterion(output, targets)\n",
    "        loss /= len(dataloader)\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch %100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss/len(dataloader)}')\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.002895166864618659\n",
      "Epoch 100/100, Loss: 3.598399302973121e-07\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "# Following the research paper's instructions\n",
    "input_size = 12\n",
    "hidden_size = 20\n",
    "num_layers = 1 # Can be changed to stack multiple LSTM layers!\n",
    "output_size = 1\n",
    "dataloader = train_loader\n",
    "#Create the model\n",
    "model = LSTM_pt(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "train(model, dataloader,num_layers, hidden_size, num_epochs = 100, learning_rate = 0.01, device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'DataLoader' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Disable gradient computation for validation\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[0;32m     17\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Reshape inputs\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'DataLoader' and 'int'"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track loss\n",
    "total_val_loss = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize hidden state and cell state\n",
    "hidden_state, cell_state = None, None  \n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        if batch_idx == len(test_loader) - 1:  \n",
    "            break  # Skip the last batch\n",
    "        inputs = inputs.unsqueeze(1).to(device)  # Reshape inputs\n",
    "        targets = targets.unsqueeze(1).to(device)\n",
    "\n",
    "        # Initialize hidden state and cell state for each batch\n",
    "        if hidden_state is not None:\n",
    "            hidden_state = hidden_state.detach()\n",
    "        if cell_state is not None:\n",
    "            cell_state = cell_state.detach()\n",
    "\n",
    "        # Forward pass\n",
    "        output, cell_state, hidden_state = model(inputs, cell_state, hidden_state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_value = criterion(output, targets)\n",
    "        total_val_loss += loss_value.item()\n",
    "        num_batches += 1\n",
    "\n",
    "# Compute average loss\n",
    "avg_val_loss = total_val_loss / num_batches\n",
    "\n",
    "# Print validation results\n",
    "print(f'Average Validation Loss: {avg_val_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
